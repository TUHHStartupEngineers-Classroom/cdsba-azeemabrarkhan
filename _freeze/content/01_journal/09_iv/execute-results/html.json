{
  "hash": "18f9b2200288495370ef5815ef45a2db",
  "result": {
    "markdown": "---\ntitle: \"Instrumental Variables\"\n---\n\n\n\n\nImagine the following situation: you have developed an app and you are already having an active user base. Of course, some users are more active than other users. Also, users might use the app for different purposes. In general, user behavior likely depends on a lot of unobserved characteristics.\n\nObviously, your goal is to keep users as long as possible on the app to maximize your ad revenues. To do that, you want to introduce a new feature and see how it affects time spent on the app. Simply comparing users who use the newly introduced feature to users who don’t would result in a biased estimate due to the unobserved confounders regarding their activity and willingness to use a new feature.\n\nTherefore, you perform a so called randomized encouragement trial, where for a random selection of users, a popup appears when opening the app and encourages these users to test new feature. The users who are not randomly selected don’t get a popup message but could also use the new feature.\n\nAfter a while you collect data on users’ activity and also if they were encouraged and if they used the new feature. To see the data, load rand_enc.rds. Do the following steps:\n\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-2_ce9e59e08eabb64397e85d2cfe91c5d2'}\n\n```{.r .cell-code}\n# reading the RDS file and print summary\ndf <- readRDS(\"../data/rand_enc.rds\")\nsummary(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     rand_enc         used_ftr       time_spent    \n#>  Min.   :0.0000   Min.   :0.000   Min.   :-1.625  \n#>  1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:17.782  \n#>  Median :1.0000   Median :0.000   Median :22.869  \n#>  Mean   :0.5068   Mean   :0.408   Mean   :23.286  \n#>  3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:28.817  \n#>  Max.   :1.0000   Max.   :1.000   Max.   :47.948\n```\n:::\n:::\n\n\n# 1\n* Draw a DAG of how you understand the relationships.\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-3_8b351941e556c5de3821b2d1428ccce0'}\n\n```{.r .cell-code}\n# Define DAG\ndag_model <- 'dag {\n  bb=\"0,0,1,1\"\n  \"Random popup\" [pos=\"0,0\"]\n  \"Use New Feature\" [exposure, pos=\"1,0\"]\n  \"Time Spent\" [outcome, pos=\"2,0\"]\n  \"Unobserved Confounders\" [pos=\"1.5,1\"]\n  \"Use New Feature\" -> \"Time Spent\"\n  \"Random popup\" -> \"Use New Feature\"\n  \"Unobserved Confounders\" -> \"Time Spent\"\n  \"Unobserved Confounders\" -> \"Use New Feature\"\n}'\n\n# draw DAG\nggdag_status(dag_model) +\n  guides(color = \"none\") +  # Turn off legend\n  theme_dag_gray()+\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges(edge_color = \"black\")\n```\n\n::: {.cell-output-display}\n![](09_iv_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n# 2\n* Compute the naive, biased estimate.\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-4_44aa8c91abbc82c1360dc9c79644a40e'}\n\n```{.r .cell-code}\nmodel_naive <- lm(time_spent ~ used_ftr, data = df)\nsummary(model_naive)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = time_spent ~ used_ftr, data = df)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -20.4950  -3.5393   0.0158   3.5961  20.5051 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 18.86993    0.06955   271.3   <2e-16 ***\n#> used_ftr    10.82269    0.10888    99.4   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 5.351 on 9998 degrees of freedom\n#> Multiple R-squared:  0.497,\tAdjusted R-squared:  0.497 \n#> F-statistic:  9881 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n# 3\n* For the assumptions that can be (partly) tested, check whether they are satisfied by either computing correlations or drawing plots. Argue whether instrumental variable estimation is an adequate procedure.\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-5_1d97901ba0fe4233dc98516c29f4e6f6'}\n\n```{.r .cell-code}\ncor(df) %>% round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>            rand_enc used_ftr time_spent\n#> rand_enc       1.00     0.20       0.13\n#> used_ftr       0.20     1.00       0.71\n#> time_spent     0.13     0.71       1.00\n```\n:::\n:::\n\nWe can see some positive coorelation between the instrumental variable (rand_enc) and exposure (used_ftr). As both are binary quantities, the scatter plot will not represent any useful information as shown below.\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-6_a5f3bb2b2d3b3c0f6d78334a18140ba7'}\n\n```{.r .cell-code}\n  ggplot(df, aes(x = rand_enc, y = used_ftr)) +\n  geom_point() +\n  labs(x = \"rand_enc 1\", y = \"used_ftr 2\", title = \"Scatter Plot of rand_enc and used_ftr\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](09_iv_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n# 4\n* Compute the IV estimate using 2SLS and compare it to the naive estimate. Would you consider the naive estimate biased, and if yes, does it have an upward or downward bias?\n\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-7_f5d5e3bccb6b13e79bb0cddc690478d1'}\n\n```{.r .cell-code}\n# Calculating manually\nfirst_stage <- lm(used_ftr ~ rand_enc, data = df)\nsummary(first_stage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = used_ftr ~ rand_enc, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -0.5071 -0.3062 -0.3062  0.4929  0.6938 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 0.306164   0.006851   44.69   <2e-16 ***\n#> rand_enc    0.200940   0.009624   20.88   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.4811 on 9998 degrees of freedom\n#> Multiple R-squared:  0.04178,\tAdjusted R-squared:  0.04169 \n#> F-statistic:   436 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsecond_stage <- lm(df$time_spent ~ first_stage$fitted.values)\nsummary(second_stage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = df$time_spent ~ first_stage$fitted.values)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -25.8757  -5.4714  -0.3263   5.3807  25.6541 \n#> \n#> Coefficients:\n#>                           Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)                19.3124     0.3129   61.72   <2e-16 ***\n#> first_stage$fitted.values   9.7382     0.7447   13.08   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 7.482 on 9998 degrees of freedom\n#> Multiple R-squared:  0.01681,\tAdjusted R-squared:  0.01672 \n#> F-statistic:   171 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-8_49aea3c57b6ead4aa1a6a99f2975dd34'}\n\n```{.r .cell-code}\n# using estimatr library\nmodel_iv <- estimatr::iv_robust(time_spent ~ used_ftr | rand_enc, data = df)\nsummary(model_iv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> estimatr::iv_robust(formula = time_spent ~ used_ftr | rand_enc, \n#>     data = df)\n#> \n#> Standard error type:  HC2 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper   DF\n#> (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#> used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#> \n#> Multiple R-squared:  0.4921 ,\tAdjusted R-squared:  0.492 \n#> F-statistic:   331 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThe estimate for used_ftr is 10.82269 in case of naive estimation and is upward biased because of unobserved confounders as compared to iv estimate of 9.7382",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}